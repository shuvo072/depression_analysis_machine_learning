{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KfxZ73-fr8Lb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RASM44_wtwup"
   },
   "outputs": [],
   "source": [
    "col_names = ['timestamp', 'which-year', 'feelings', 'scale', 'gender', 'age', 'location', 'status', 'finance', 'copeup', 'understanding', 'pressure', 'result', 'livingplace', 'supports', 'smedia', 'compare', 'meal', 'health', 'hobby', 'sleep']\n",
    "# load dataset\n",
    "depression = pd.read_csv(\"Depression and Happiness Factor Analysis.csv\",names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "TvP2BphJuB1e",
    "outputId": "822c271b-f08b-4964-ddee-7535ddeaee32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>which-year</th>\n",
       "      <th>feelings</th>\n",
       "      <th>scale</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>location</th>\n",
       "      <th>status</th>\n",
       "      <th>finance</th>\n",
       "      <th>copeup</th>\n",
       "      <th>understanding</th>\n",
       "      <th>pressure</th>\n",
       "      <th>result</th>\n",
       "      <th>livingplace</th>\n",
       "      <th>supports</th>\n",
       "      <th>smedia</th>\n",
       "      <th>compare</th>\n",
       "      <th>meal</th>\n",
       "      <th>health</th>\n",
       "      <th>hobby</th>\n",
       "      <th>sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     which-year  feelings  scale  gender  age  location  status  finance  \\\n",
       "1             0         2     80       0    3         2       1        0   \n",
       "2             1         1     91       0    2         1       3        1   \n",
       "3             2         2     47       0    1         2       1        0   \n",
       "4             3         3      0       0    3         2       0        0   \n",
       "5             2         0     14       0    3         2       1        0   \n",
       "..          ...       ...    ...     ...  ...       ...     ...      ...   \n",
       "746           3         0     20       0    3         1       3        1   \n",
       "747           3         0     32       0    3         1       3        1   \n",
       "748           3         1     71       0    3         0       3        1   \n",
       "749           3         1     89       0    3         1       3        1   \n",
       "750           3         2     64       0    3         0       3        1   \n",
       "\n",
       "     copeup  understanding  pressure  result  livingplace  supports  smedia  \\\n",
       "1         3              2         1       2            1         1       0   \n",
       "2         2              1         0       0            1         0       0   \n",
       "3         2              2         2       2            0         0       0   \n",
       "4         0              0         2       0            0         2       0   \n",
       "5         4              1         2       0            1         2       0   \n",
       "..      ...            ...       ...     ...          ...       ...     ...   \n",
       "746       2              2         2       0            0         0       0   \n",
       "747       1              2         2       0            0         0       0   \n",
       "748       3              1         0       0            1         0       0   \n",
       "749       2              1         0       0            1         1       0   \n",
       "750       2              2         0       2            1         0       0   \n",
       "\n",
       "     compare  meal  health  hobby  sleep  \n",
       "1          2     2       0      0     10  \n",
       "2          0     1       1      1      6  \n",
       "3          2     0       1      1      9  \n",
       "4          2     1       1      0      4  \n",
       "5          2     1       1      0      1  \n",
       "..       ...   ...     ...    ...    ...  \n",
       "746        1     2       0      1      4  \n",
       "747        0     1       0      1      3  \n",
       "748        1     2       0      0      7  \n",
       "749        1     0       0      1     10  \n",
       "750        1     0       1      0      6  \n",
       "\n",
       "[750 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression.drop([0], axis=0, inplace=True)\n",
    "depression.drop(['timestamp'], axis=1, inplace=True)\n",
    "# depression.head()\n",
    "\n",
    "dataset_encoded=depression.iloc[:,0:20]\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for i in dataset_encoded:\n",
    "    dataset_encoded[i]=le.fit_transform(dataset_encoded[i].astype(str))\n",
    "\n",
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vGlYoQEwfBH",
    "outputId": "5806cc37-7e9b-4194-a8de-07a12efb247a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['which-year', 'scale', 'gender', 'age', 'location', 'status', 'finance', 'copeup', 'understanding', 'pressure', 'result', 'livingplace', 'supports', 'smedia', 'compare', 'meal', 'health', 'hobby', 'sleep']\n",
    "X = dataset_encoded[feature_cols] # Features\n",
    "y = dataset_encoded.feelings # Target variable\n",
    "\n",
    "one_hot = pd.get_dummies(y)\n",
    "\n",
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "22A7Di1_wokL"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, one_hot, test_size=0.3, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoeH__QHw70d",
    "outputId": "8b396f12-1e87-41cf-97aa-67531d7e8f91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xS82bcDoxHEq",
    "outputId": "21b3d634-4436-40df-e685-e4f70c4036f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_VKhc6I6xR-f"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEc2Yt1pxU-_",
    "outputId": "e32dff30-c846-4574-dcd9-e987a076f5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                252       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 65        \n",
      "=================================================================\n",
      "Total params: 873\n",
      "Trainable params: 873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(20, input_dim=19, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(12,  activation=\"relu\"))\n",
    "model.add(Dense(12,  activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5M3DZPfJyH4e",
    "outputId": "1b1988a2-5d8a-4d40-b612-a237be02d71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "12/12 [==============================] - 2s 117ms/step - loss: 5.0346 - accuracy: 0.3061 - val_loss: 3.0651 - val_accuracy: 0.2848\n",
      "Epoch 2/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.1254 - accuracy: 0.2839 - val_loss: 2.3581 - val_accuracy: 0.3418\n",
      "Epoch 3/80\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4682 - accuracy: 0.3268 - val_loss: 1.7808 - val_accuracy: 0.3608\n",
      "Epoch 4/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6666 - accuracy: 0.3443 - val_loss: 1.4539 - val_accuracy: 0.3354\n",
      "Epoch 5/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4199 - accuracy: 0.3341 - val_loss: 1.3715 - val_accuracy: 0.3165\n",
      "Epoch 6/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3463 - accuracy: 0.3223 - val_loss: 1.3083 - val_accuracy: 0.3354\n",
      "Epoch 7/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3047 - accuracy: 0.3162 - val_loss: 1.2583 - val_accuracy: 0.3418\n",
      "Epoch 8/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2265 - accuracy: 0.3483 - val_loss: 1.2142 - val_accuracy: 0.3418\n",
      "Epoch 9/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2196 - accuracy: 0.3229 - val_loss: 1.1800 - val_accuracy: 0.3418\n",
      "Epoch 10/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1209 - accuracy: 0.3723 - val_loss: 1.1520 - val_accuracy: 0.3481\n",
      "Epoch 11/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1392 - accuracy: 0.3241 - val_loss: 1.1259 - val_accuracy: 0.3608\n",
      "Epoch 12/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1042 - accuracy: 0.3980 - val_loss: 1.1076 - val_accuracy: 0.4114\n",
      "Epoch 13/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0130 - accuracy: 0.4786 - val_loss: 1.0762 - val_accuracy: 0.4430\n",
      "Epoch 14/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0655 - accuracy: 0.4680 - val_loss: 1.0510 - val_accuracy: 0.4620\n",
      "Epoch 15/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9738 - accuracy: 0.5128 - val_loss: 1.0311 - val_accuracy: 0.4747\n",
      "Epoch 16/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0144 - accuracy: 0.5025 - val_loss: 1.0103 - val_accuracy: 0.4873\n",
      "Epoch 17/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9719 - accuracy: 0.5392 - val_loss: 0.9894 - val_accuracy: 0.4873\n",
      "Epoch 18/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9432 - accuracy: 0.5313 - val_loss: 0.9717 - val_accuracy: 0.4937\n",
      "Epoch 19/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9339 - accuracy: 0.5084 - val_loss: 0.9543 - val_accuracy: 0.4937\n",
      "Epoch 20/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9316 - accuracy: 0.5704 - val_loss: 0.9415 - val_accuracy: 0.4937\n",
      "Epoch 21/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9231 - accuracy: 0.5204 - val_loss: 0.9189 - val_accuracy: 0.5443\n",
      "Epoch 22/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8657 - accuracy: 0.5730 - val_loss: 0.9053 - val_accuracy: 0.5570\n",
      "Epoch 23/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8904 - accuracy: 0.6141 - val_loss: 0.9023 - val_accuracy: 0.5127\n",
      "Epoch 24/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8405 - accuracy: 0.5522 - val_loss: 0.8812 - val_accuracy: 0.6646\n",
      "Epoch 25/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8395 - accuracy: 0.7015 - val_loss: 0.8601 - val_accuracy: 0.5696\n",
      "Epoch 26/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8298 - accuracy: 0.6531 - val_loss: 0.8396 - val_accuracy: 0.6582\n",
      "Epoch 27/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8039 - accuracy: 0.7052 - val_loss: 0.8257 - val_accuracy: 0.6899\n",
      "Epoch 28/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8085 - accuracy: 0.7174 - val_loss: 0.8105 - val_accuracy: 0.6519\n",
      "Epoch 29/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7844 - accuracy: 0.7221 - val_loss: 0.7981 - val_accuracy: 0.7025\n",
      "Epoch 30/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7546 - accuracy: 0.7621 - val_loss: 0.7778 - val_accuracy: 0.6899\n",
      "Epoch 31/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7689 - val_loss: 0.7621 - val_accuracy: 0.6962\n",
      "Epoch 32/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7181 - accuracy: 0.7779 - val_loss: 0.7502 - val_accuracy: 0.6899\n",
      "Epoch 33/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.7917 - val_loss: 0.7224 - val_accuracy: 0.7405\n",
      "Epoch 34/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.8047 - val_loss: 0.6979 - val_accuracy: 0.7468\n",
      "Epoch 35/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.7870 - val_loss: 0.6775 - val_accuracy: 0.7405\n",
      "Epoch 36/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.7978 - val_loss: 0.6476 - val_accuracy: 0.7658\n",
      "Epoch 37/80\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.7768 - val_loss: 0.6545 - val_accuracy: 0.7911\n",
      "Epoch 38/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.7623 - val_loss: 0.6286 - val_accuracy: 0.7342\n",
      "Epoch 39/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7898 - val_loss: 0.6065 - val_accuracy: 0.7975\n",
      "Epoch 40/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.8097 - val_loss: 0.5793 - val_accuracy: 0.8038\n",
      "Epoch 41/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.8334 - val_loss: 0.5664 - val_accuracy: 0.7911\n",
      "Epoch 42/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.8261 - val_loss: 0.5555 - val_accuracy: 0.7975\n",
      "Epoch 43/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.8059 - val_loss: 0.5593 - val_accuracy: 0.7848\n",
      "Epoch 44/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7743 - val_loss: 0.5369 - val_accuracy: 0.8101\n",
      "Epoch 45/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7664 - val_loss: 0.5292 - val_accuracy: 0.8418\n",
      "Epoch 46/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.8156 - val_loss: 0.5397 - val_accuracy: 0.7658\n",
      "Epoch 47/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7975 - val_loss: 0.5101 - val_accuracy: 0.8418\n",
      "Epoch 48/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8399 - val_loss: 0.4942 - val_accuracy: 0.8228\n",
      "Epoch 49/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.8189 - val_loss: 0.4900 - val_accuracy: 0.8354\n",
      "Epoch 50/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.8472 - val_loss: 0.4775 - val_accuracy: 0.8101\n",
      "Epoch 51/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8794 - val_loss: 0.4748 - val_accuracy: 0.8418\n",
      "Epoch 52/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8561 - val_loss: 0.4729 - val_accuracy: 0.8165\n",
      "Epoch 53/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8722 - val_loss: 0.4701 - val_accuracy: 0.8418\n",
      "Epoch 54/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8320 - val_loss: 0.4607 - val_accuracy: 0.8228\n",
      "Epoch 55/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8501 - val_loss: 0.4548 - val_accuracy: 0.8481\n",
      "Epoch 56/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8491 - val_loss: 0.4466 - val_accuracy: 0.8481\n",
      "Epoch 57/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8588 - val_loss: 0.4453 - val_accuracy: 0.8544\n",
      "Epoch 58/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8671 - val_loss: 0.4291 - val_accuracy: 0.8544\n",
      "Epoch 59/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8753 - val_loss: 0.4306 - val_accuracy: 0.8544\n",
      "Epoch 60/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8347 - val_loss: 0.4290 - val_accuracy: 0.8481\n",
      "Epoch 61/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8429 - val_loss: 0.4213 - val_accuracy: 0.8608\n",
      "Epoch 62/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8824 - val_loss: 0.4126 - val_accuracy: 0.8797\n",
      "Epoch 63/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8427 - val_loss: 0.4108 - val_accuracy: 0.8734\n",
      "Epoch 64/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8671 - val_loss: 0.4386 - val_accuracy: 0.7975\n",
      "Epoch 65/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8785 - val_loss: 0.4434 - val_accuracy: 0.8038\n",
      "Epoch 66/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8627 - val_loss: 0.4040 - val_accuracy: 0.8671\n",
      "Epoch 67/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8757 - val_loss: 0.4079 - val_accuracy: 0.8544\n",
      "Epoch 68/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8585 - val_loss: 0.3990 - val_accuracy: 0.8797\n",
      "Epoch 69/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8626 - val_loss: 0.3911 - val_accuracy: 0.8671\n",
      "Epoch 70/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8730 - val_loss: 0.3877 - val_accuracy: 0.8671\n",
      "Epoch 71/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8561 - val_loss: 0.4404 - val_accuracy: 0.7975\n",
      "Epoch 72/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8614 - val_loss: 0.4160 - val_accuracy: 0.8165\n",
      "Epoch 73/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8637 - val_loss: 0.3913 - val_accuracy: 0.8797\n",
      "Epoch 74/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8844 - val_loss: 0.3787 - val_accuracy: 0.8861\n",
      "Epoch 75/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8901 - val_loss: 0.3758 - val_accuracy: 0.8797\n",
      "Epoch 76/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8673 - val_loss: 0.3836 - val_accuracy: 0.8924\n",
      "Epoch 77/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8956 - val_loss: 0.3708 - val_accuracy: 0.8797\n",
      "Epoch 78/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8974 - val_loss: 0.3737 - val_accuracy: 0.8797\n",
      "Epoch 79/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.9049 - val_loss: 0.3818 - val_accuracy: 0.8734\n",
      "Epoch 80/80\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.9158 - val_loss: 0.3616 - val_accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "model_result = model.fit(X_train, y_train, epochs=80, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVpKf8BRzEVS",
    "outputId": "e96221f5-a100-433f-a2ef-137c85135f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 572us/step - loss: 0.4696 - accuracy: 0.8311\n",
      "Test set\n",
      "  Loss: 0.470\n",
      "  Accuracy: 0.831\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
